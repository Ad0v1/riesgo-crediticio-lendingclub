# Predicci√≥n de Riesgo Crediticio en LendingClub

Este repositorio contiene un proyecto completo de Machine Learning orientado a predecir el incumplimiento de pagos de pr√©stamos, utilizando datos hist√≥ricos de LendingClub. Se incluye un pipeline CI/CD automatizado con GitHub Actions que realiza todo el flujo de trabajo: desde el an√°lisis exploratorio hasta la predicci√≥n final.

---

## Estructura del Proyecto
riesgo-crediticio-lendingclub/
‚îú‚îÄ‚îÄ data/ # Dataset original (input)
‚îú‚îÄ‚îÄ eda/
‚îÇ ‚îî‚îÄ‚îÄ eda.py # Script de An√°lisis Exploratorio (EDA)
‚îú‚îÄ‚îÄ preprocessing/
‚îÇ ‚îî‚îÄ‚îÄ preprocessing.py # Limpieza, imputaci√≥n y transformaci√≥n
‚îú‚îÄ‚îÄ training/
‚îÇ ‚îî‚îÄ‚îÄ train_model.py # Entrenamiento del modelo y predicciones
‚îú‚îÄ‚îÄ visualization/ # Gr√°ficas de m√©tricas (opcional)
‚îú‚îÄ‚îÄ reporte_eda_dataset.html # Reporte visual generado por EDA
‚îú‚îÄ‚îÄ prediccion_prestamos.csv # Predicciones del modelo
‚îú‚îÄ‚îÄ requirements.txt # Librer√≠as necesarias
‚îî‚îÄ‚îÄ .github/workflows/ci.yml # Archivo del pipeline CI/CD


---

## ‚öôÔ∏è Pipeline CI/CD con GitHub Actions

Cada vez que se hace un `push` a la rama `main`, se ejecuta autom√°ticamente un flujo de trabajo (`ci.yml`) que realiza las siguientes tareas:

### üß© Pasos del pipeline

1. **Checkout del c√≥digo fuente**
2. **Configuraci√≥n del entorno Python (v3.10)**
3. **Creaci√≥n y activaci√≥n de un entorno virtual**
4. **Instalaci√≥n de dependencias (`requirements.txt`)**
5. **Ejecuci√≥n del An√°lisis Exploratorio de Datos (EDA)**  
   ‚Üí Genera `reporte_eda_dataset.html`
6. **Preprocesamiento de los datos**  
   ‚Üí Limpieza, imputaci√≥n y transformaci√≥n.
7. **Entrenamiento del modelo y generaci√≥n de predicciones**  
   ‚Üí Genera `prediccion_prestamos.csv`
8. **Carga de artefactos**  
   ‚Üí Ambos archivos son exportados como artefactos accesibles desde GitHub Actions.

---

## Artefactos del Pipeline

Tras ejecutarse el pipeline, se generan:

- `reporte_eda_dataset.html` ‚Üí Reporte autom√°tico visual del dataset.
- `prediccion_prestamos.csv` ‚Üí Archivo con los resultados del modelo entrenado.

Estos archivos pueden descargarse desde la secci√≥n **Artifacts** en la interfaz de GitHub Actions.

---

## üíª Ejecuci√≥n local del proyecto

Si deseas ejecutar este proyecto en tu m√°quina local:

### 1. Clona el repositorio
```bash
git clone https://github.com/usuario/riesgo-crediticio-lendingclub.git
cd riesgo-crediticio-lendingclub
python -m venv venv
source venv/bin/activate     # En Windows: venv\Scripts\activate
pip install -r requirements.txt
python eda/eda.py
python preprocessing/preprocessing.py
python training/train_model.py

DOCUMENTACION DESCRIPTIVA:
3. Implementaci√≥n del Pipeline CI/CD
3.1. Descripci√≥n General
Con el objetivo de automatizar el flujo completo de procesamiento y modelado de datos, se implement√≥ un pipeline CI/CD utilizando GitHub Actions. Este pipeline se activa autom√°ticamente al realizar un push a la rama principal (main), lo que permite ejecutar los scripts de an√°lisis, preprocesamiento, entrenamiento y exportaci√≥n de predicciones de forma secuencial y sin intervenci√≥n manual.

3.2. Estructura del Pipeline
El pipeline se encuentra definido en el archivo ci.yml dentro del directorio .github/workflows/. Este archivo establece la secuencia de tareas que GitHub ejecuta en un entorno Linux (ubuntu-latest), con Python 3.10 y las dependencias especificadas en requirements.txt.

3.3. Pasos del Pipeline
A continuaci√≥n, se detalla cada uno de los pasos automatizados que ejecuta el pipeline:

Check out del c√≥digo: Se utiliza la acci√≥n actions/checkout@v4 para clonar el repositorio y acceder a los archivos del proyecto.

Configuraci√≥n de Python: Se instala la versi√≥n 3.10 de Python mediante actions/setup-python@v4.

Instalaci√≥n de dependencias:
Se crea y activa un entorno virtual (virtualenv), y luego se instalan las librer√≠as necesarias con pip install -r requirements.txt.

Ejecuci√≥n del An√°lisis Exploratorio de Datos (EDA):
Se ejecuta el script eda.py, ubicado en la carpeta eda/. Este script genera un reporte visual (reporte_eda_dataset.html) que analiza autom√°ticamente la distribuci√≥n, valores faltantes y correlaciones del dataset.

Preprocesamiento de datos:
El script preprocessing.py realiza tareas de limpieza, imputaci√≥n de datos faltantes, codificaci√≥n de variables categ√≥ricas y estandarizaci√≥n de variables num√©ricas.

Entrenamiento del modelo y predicci√≥n:
El archivo train_model.py se encarga de entrenar el modelo de regresi√≥n log√≠stica con los datos ya procesados. Adem√°s, genera un archivo CSV (prediccion_prestamos.csv) con las predicciones finales.

Carga de artefactos (Outputs):
Se utiliza la acci√≥n actions/upload-artifact@v4 para exportar los archivos generados (reporte_eda_dataset.html y prediccion_prestamos.csv) como artefactos descargables desde la secci√≥n de GitHub Actions.


